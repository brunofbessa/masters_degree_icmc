{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfceb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c50d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-04-30 14:12:21 - Mod: 125686976 - Func: <module> - Line: 72]: Running experiments on datasets with heterographs and GNNs.\n",
      "[INFO][2023-04-30 14:12:21 - Mod: 125686976 - Func: run_experiment_gnn - Line: 25]: Loaded preprocessed heterographs classic4_K_50_Kc_400_docf_replace_docst_0.5.\n",
      "  0%|                                                  | 0/1500 [00:00<?, ?it/s][INFO][2023-04-30 14:12:25 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.1242, Loss (test): 1.1528, F1 (train): 0.2960, F1 (test): 0.0702\n",
      "  0%|                                        | 1/1500 [00:03<1:19:09,  3.17s/it][INFO][2023-04-30 14:12:28 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0887, Loss (test): 1.1737, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 2/1500 [00:06<1:15:11,  3.01s/it][INFO][2023-04-30 14:12:30 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0610, Loss (test): 1.2122, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 3/1500 [00:08<1:13:35,  2.95s/it][INFO][2023-04-30 14:12:33 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0385, Loss (test): 1.2812, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 4/1500 [00:11<1:13:11,  2.94s/it][INFO][2023-04-30 14:12:36 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0318, Loss (test): 1.3286, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 5/1500 [00:14<1:12:12,  2.90s/it][INFO][2023-04-30 14:12:39 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0367, Loss (test): 1.3140, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 6/1500 [00:17<1:12:43,  2.92s/it][INFO][2023-04-30 14:12:42 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0313, Loss (test): 1.2710, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 7/1500 [00:20<1:12:31,  2.91s/it][INFO][2023-04-30 14:12:45 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0186, Loss (test): 1.2337, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▏                                       | 8/1500 [00:23<1:12:45,  2.93s/it][INFO][2023-04-30 14:12:48 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0094, Loss (test): 1.2091, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▏                                       | 9/1500 [00:26<1:12:52,  2.93s/it][INFO][2023-04-30 14:12:51 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0057, Loss (test): 1.2005, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 10/1500 [00:29<1:13:46,  2.97s/it][INFO][2023-04-30 14:12:54 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0013, Loss (test): 1.2020, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 11/1500 [00:32<1:13:09,  2.95s/it][INFO][2023-04-30 14:12:57 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9916, Loss (test): 1.2182, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 12/1500 [00:35<1:13:21,  2.96s/it][INFO][2023-04-30 14:13:00 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9801, Loss (test): 1.2437, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 13/1500 [00:38<1:13:20,  2.96s/it][INFO][2023-04-30 14:13:03 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9654, Loss (test): 1.2776, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 14/1500 [00:41<1:13:05,  2.95s/it][INFO][2023-04-30 14:13:06 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9522, Loss (test): 1.3046, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 15/1500 [00:44<1:12:48,  2.94s/it][INFO][2023-04-30 14:13:09 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9401, Loss (test): 1.3103, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 16/1500 [00:47<1:13:06,  2.96s/it][INFO][2023-04-30 14:13:12 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9209, Loss (test): 1.3003, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 17/1500 [00:50<1:14:07,  3.00s/it][INFO][2023-04-30 14:13:15 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8958, Loss (test): 1.2724, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 18/1500 [00:53<1:14:38,  3.02s/it][INFO][2023-04-30 14:13:18 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8709, Loss (test): 1.2632, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 19/1500 [00:56<1:14:18,  3.01s/it][INFO][2023-04-30 14:13:21 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8444, Loss (test): 1.2877, F1 (train): 0.2834, F1 (test): 0.0738\n",
      "  1%|▌                                      | 20/1500 [00:59<1:13:59,  3.00s/it][INFO][2023-04-30 14:13:24 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8152, Loss (test): 1.3480, F1 (train): 0.3108, F1 (test): 0.0838\n",
      "  1%|▌                                      | 21/1500 [01:02<1:13:43,  2.99s/it][INFO][2023-04-30 14:13:27 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.7801, Loss (test): 1.4255, F1 (train): 0.3354, F1 (test): 0.0887\n",
      "  1%|▌                                      | 22/1500 [01:05<1:13:39,  2.99s/it][INFO][2023-04-30 14:13:30 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.7478, Loss (test): 1.4694, F1 (train): 0.3640, F1 (test): 0.0943\n",
      "  2%|▌                                      | 23/1500 [01:08<1:13:22,  2.98s/it][INFO][2023-04-30 14:13:33 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.7119, Loss (test): 1.4481, F1 (train): 0.4267, F1 (test): 0.1143\n",
      "  2%|▌                                      | 24/1500 [01:11<1:13:12,  2.98s/it][INFO][2023-04-30 14:13:36 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.6739, Loss (test): 1.4796, F1 (train): 0.4861, F1 (test): 0.1229\n",
      "  2%|▋                                      | 25/1500 [01:14<1:13:09,  2.98s/it][INFO][2023-04-30 14:13:39 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.6405, Loss (test): 1.5863, F1 (train): 0.4972, F1 (test): 0.1238\n",
      "  2%|▋                                      | 26/1500 [01:17<1:13:05,  2.98s/it][INFO][2023-04-30 14:13:42 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.6066, Loss (test): 1.7133, F1 (train): 0.4961, F1 (test): 0.1283\n",
      "  2%|▋                                      | 27/1500 [01:20<1:13:31,  3.00s/it][INFO][2023-04-30 14:13:45 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.5729, Loss (test): 1.7416, F1 (train): 0.4953, F1 (test): 0.1365\n",
      "  2%|▋                                      | 28/1500 [01:23<1:14:25,  3.03s/it][INFO][2023-04-30 14:13:48 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.5357, Loss (test): 1.7293, F1 (train): 0.5185, F1 (test): 0.1522\n",
      "  2%|▊                                      | 29/1500 [01:26<1:13:53,  3.01s/it][INFO][2023-04-30 14:13:51 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.5002, Loss (test): 1.8357, F1 (train): 0.5796, F1 (test): 0.1560\n",
      "  2%|▊                                      | 30/1500 [01:29<1:13:35,  3.00s/it][INFO][2023-04-30 14:13:54 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.4607, Loss (test): 1.9936, F1 (train): 0.6252, F1 (test): 0.1579\n",
      "  2%|▊                                      | 31/1500 [01:32<1:13:10,  2.99s/it][INFO][2023-04-30 14:13:57 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.4233, Loss (test): 2.0810, F1 (train): 0.6783, F1 (test): 0.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 32/1500 [01:35<1:12:54,  2.98s/it][INFO][2023-04-30 14:14:00 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.3836, Loss (test): 2.0973, F1 (train): 0.7785, F1 (test): 0.1617\n",
      "  2%|▊                                      | 33/1500 [01:38<1:12:41,  2.97s/it][INFO][2023-04-30 14:14:03 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.3473, Loss (test): 2.2711, F1 (train): 0.8537, F1 (test): 0.1480\n",
      "  2%|▉                                      | 34/1500 [01:41<1:12:22,  2.96s/it][INFO][2023-04-30 14:14:06 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.3081, Loss (test): 2.5020, F1 (train): 0.8954, F1 (test): 0.1418\n",
      "  2%|▉                                      | 35/1500 [01:44<1:12:12,  2.96s/it][INFO][2023-04-30 14:14:08 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.2684, Loss (test): 2.5937, F1 (train): 0.8927, F1 (test): 0.1436\n",
      "  2%|▉                                      | 36/1500 [01:46<1:12:01,  2.95s/it][INFO][2023-04-30 14:14:11 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.2363, Loss (test): 2.7102, F1 (train): 0.9173, F1 (test): 0.1362\n",
      "  2%|▉                                      | 37/1500 [01:49<1:12:12,  2.96s/it][INFO][2023-04-30 14:14:15 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.2120, Loss (test): 2.9252, F1 (train): 0.9209, F1 (test): 0.1366\n",
      "  3%|▉                                      | 38/1500 [01:53<1:13:18,  3.01s/it][INFO][2023-04-30 14:14:18 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1902, Loss (test): 3.1131, F1 (train): 0.9162, F1 (test): 0.1413\n",
      "  3%|█                                      | 39/1500 [01:56<1:12:43,  2.99s/it][INFO][2023-04-30 14:14:20 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1719, Loss (test): 3.2297, F1 (train): 0.9255, F1 (test): 0.1440\n",
      "  3%|█                                      | 40/1500 [01:58<1:12:20,  2.97s/it][INFO][2023-04-30 14:14:23 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1595, Loss (test): 3.2513, F1 (train): 0.9238, F1 (test): 0.1440\n",
      "  3%|█                                      | 41/1500 [02:01<1:12:04,  2.96s/it][INFO][2023-04-30 14:14:26 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1533, Loss (test): 3.4244, F1 (train): 0.9248, F1 (test): 0.1373\n",
      "  3%|█                                      | 42/1500 [02:04<1:11:47,  2.95s/it][INFO][2023-04-30 14:14:29 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1509, Loss (test): 3.6687, F1 (train): 0.9179, F1 (test): 0.1305\n",
      "  3%|█                                      | 43/1500 [02:07<1:11:43,  2.95s/it][INFO][2023-04-30 14:14:32 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1566, Loss (test): 3.8784, F1 (train): 0.9161, F1 (test): 0.1300\n",
      "  3%|█▏                                     | 44/1500 [02:10<1:11:21,  2.94s/it][INFO][2023-04-30 14:14:35 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1478, Loss (test): 3.9666, F1 (train): 0.9162, F1 (test): 0.1337\n",
      "  3%|█▏                                     | 45/1500 [02:13<1:11:08,  2.93s/it][INFO][2023-04-30 14:14:38 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1344, Loss (test): 3.9000, F1 (train): 0.9275, F1 (test): 0.1364\n",
      "  3%|█▏                                     | 46/1500 [02:16<1:11:00,  2.93s/it][INFO][2023-04-30 14:14:41 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1391, Loss (test): 3.9698, F1 (train): 0.9286, F1 (test): 0.1355\n",
      "  3%|█▏                                     | 47/1500 [02:19<1:11:13,  2.94s/it][INFO][2023-04-30 14:14:44 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.1339, Loss (test): 4.1553, F1 (train): 0.9288, F1 (test): 0.1357\n",
      "  3%|█▏                                     | 48/1500 [02:22<1:12:46,  3.01s/it][ERROR][2023-04-30 14:14:47 - Mod: gnn - Func: test_model - Line: 131]: Error testing model: \n",
      " The predictions values should be between 0 and 1,                 make sure to pass the values to sigmoid for binary                 classification or softmax for multi-class classification\n",
      "  3%|█▏                                     | 48/1500 [02:25<1:13:29,  3.04s/it]\n",
      "[ERROR][2023-04-30 14:14:47 - Mod: functions - Func: run_heterognn_splitted - Line: 711]: Error training model on heterodata: \n",
      " The predictions values should be between 0 and 1,                 make sure to pass the values to sigmoid for binary                 classification or softmax for multi-class classification\n",
      "[INFO][2023-04-30 14:14:47 - Mod: 125686976 - Func: run_experiment_gnn - Line: 54]: Error occurred: \n",
      "cannot unpack non-iterable NoneType object\n",
      "[INFO][2023-04-30 14:14:47 - Mod: 125686976 - Func: run_experiment_gnn - Line: 25]: Loaded preprocessed heterographs classic4_K_50_Kc_400_docf_replace_docst_0.5.\n",
      "  0%|                                                  | 0/1500 [00:00<?, ?it/s][INFO][2023-04-30 14:14:54 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.1592, Loss (test): 1.1474, F1 (train): 0.0898, F1 (test): 0.0702\n",
      "  0%|                                        | 1/1500 [00:07<2:57:05,  7.09s/it][INFO][2023-04-30 14:15:02 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0643, Loss (test): 1.2646, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 2/1500 [00:14<2:58:45,  7.16s/it][INFO][2023-04-30 14:15:09 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0367, Loss (test): 1.3333, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 3/1500 [00:21<3:02:14,  7.30s/it][INFO][2023-04-30 14:15:16 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0454, Loss (test): 1.2737, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|                                        | 4/1500 [00:28<3:00:07,  7.22s/it][INFO][2023-04-30 14:15:23 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0259, Loss (test): 1.2214, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 5/1500 [00:36<2:59:47,  7.22s/it][INFO][2023-04-30 14:15:31 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0199, Loss (test): 1.1938, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 6/1500 [00:43<3:00:39,  7.26s/it][INFO][2023-04-30 14:15:38 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0178, Loss (test): 1.1913, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  0%|▏                                       | 7/1500 [00:50<3:02:13,  7.32s/it][INFO][2023-04-30 14:15:46 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 1.0083, Loss (test): 1.2113, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▏                                       | 8/1500 [00:58<3:02:45,  7.35s/it][INFO][2023-04-30 14:15:53 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9958, Loss (test): 1.2495, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▏                                       | 9/1500 [01:05<3:02:25,  7.34s/it][INFO][2023-04-30 14:16:00 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9861, Loss (test): 1.2896, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 10/1500 [01:12<2:59:46,  7.24s/it][INFO][2023-04-30 14:16:07 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9775, Loss (test): 1.2991, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 11/1500 [01:19<2:58:42,  7.20s/it][INFO][2023-04-30 14:16:14 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9603, Loss (test): 1.2731, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 12/1500 [01:26<2:57:59,  7.18s/it][INFO][2023-04-30 14:16:21 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9376, Loss (test): 1.2455, F1 (train): 0.2809, F1 (test): 0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 13/1500 [01:33<2:56:56,  7.14s/it][INFO][2023-04-30 14:16:28 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.9176, Loss (test): 1.2328, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▎                                      | 14/1500 [01:41<2:56:48,  7.14s/it][INFO][2023-04-30 14:16:36 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8931, Loss (test): 1.2445, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 15/1500 [01:48<2:58:03,  7.19s/it][INFO][2023-04-30 14:16:43 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8636, Loss (test): 1.2800, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 16/1500 [01:56<3:02:07,  7.36s/it][INFO][2023-04-30 14:16:50 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.8282, Loss (test): 1.3075, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 17/1500 [02:03<2:59:28,  7.26s/it][INFO][2023-04-30 14:16:57 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.7874, Loss (test): 1.3063, F1 (train): 0.2809, F1 (test): 0.0702\n",
      "  1%|▍                                      | 18/1500 [02:09<2:56:11,  7.13s/it][INFO][2023-04-30 14:17:04 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.7445, Loss (test): 1.3161, F1 (train): 0.2885, F1 (test): 0.0761\n",
      "  1%|▍                                      | 19/1500 [02:16<2:54:27,  7.07s/it][INFO][2023-04-30 14:17:11 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.6964, Loss (test): 1.3764, F1 (train): 0.3891, F1 (test): 0.0832\n",
      "  1%|▌                                      | 20/1500 [02:23<2:53:07,  7.02s/it][INFO][2023-04-30 14:17:18 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.6461, Loss (test): 1.4119, F1 (train): 0.4372, F1 (test): 0.0907\n",
      "  1%|▌                                      | 21/1500 [02:31<2:54:55,  7.10s/it][INFO][2023-04-30 14:17:26 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.5946, Loss (test): 1.4343, F1 (train): 0.6372, F1 (test): 0.1043\n",
      "  1%|▌                                      | 22/1500 [02:38<2:55:42,  7.13s/it][INFO][2023-04-30 14:17:33 - Mod: functions - Func: run_heterognn_splitted - Line: 696]: Loss (train): 0.5482, Loss (test): 1.5337, F1 (train): 0.8086, F1 (test): 0.1035\n",
      "  2%|▌                                      | 23/1500 [02:46<2:58:39,  7.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m activation \u001b[38;5;129;01min\u001b[39;00m activation_list:\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m version \u001b[38;5;129;01min\u001b[39;00m gnn_version_list:\n\u001b[0;32m---> 77\u001b[0m                 \u001b[43mrun_experiment_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mp_dropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mKc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdocf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdocst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip -r /content/csv_objects.zip /content/csv_objects\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp /content/csv_objects.zip  /content/drive/MyDrive/project\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m, in \u001b[0;36mrun_experiment_gnn\u001b[0;34m(database_name, K, hidden_channels, num_layers, p_dropout, Kc, docf, docst, activation, version, num_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded preprocessed heterographs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheterodata_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m training_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheterodata_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_act_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ver_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 29\u001b[0m df_experiment \u001b[38;5;241m=\u001b[39m \u001b[43mrun_heterognn_splitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mheterodata_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheterodata_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mheterodata_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheterodata_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mp_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m loss_test, micro_test, acc_test, epoch_convergence \u001b[38;5;241m=\u001b[39m df_experiment\n\u001b[1;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_channels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_dropout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_test\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_test\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_test\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_convergence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/study/mestrado/masters_degree_icmc/project/functions.py:677\u001b[0m, in \u001b[0;36mrun_heterognn_splitted\u001b[0;34m(database_name, description, heterodata_train, heterodata_test, hidden_channels, num_layers, p_dropout, num_epochs, aggr, version, activation, verbose)\u001b[0m\n\u001b[1;32m    674\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(num_epochs):\n\u001b[0;32m--> 677\u001b[0m     loss_train, micro_train, acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheterodata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m     loss_test, micro_test, acc_test \u001b[38;5;241m=\u001b[39m test_model(model, heterodata_test, activation\u001b[38;5;241m=\u001b[39mactivation)\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_train \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m min_loss \u001b[38;5;129;01mand\u001b[39;00m acc_test \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_acc:\n",
      "File \u001b[0;32m~/Documents/study/mestrado/masters_degree_icmc/project/gnn.py:80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, optimizer, activation)\u001b[0m\n\u001b[1;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     79\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m prediction \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mce\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/study/mestrado/masters_degree_icmc/project/gnn.py:65\u001b[0m, in \u001b[0;36mHeteroGNN.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 65\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: F\u001b[38;5;241m.\u001b[39mleaky_relu(x) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     67\u001b[0m         x_dict \u001b[38;5;241m=\u001b[39m {key: F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_dropout) \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/hetero_conv.py:125\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, x_dict, edge_index_dict, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    123\u001b[0m         out \u001b[38;5;241m=\u001b[39m conv(x_dict[src], edge_index, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     out_dict[dst]\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m out_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/sage_conv.py:80\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     77\u001b[0m     x: OptPairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m     83\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:309\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    307\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 309\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__collect__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__user_args__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:202\u001b[0m, in \u001b[0;36mMessagePassing.__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_size__(size, dim, data)\n\u001b[0;32m--> 202\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__lift__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:172\u001b[0m, in \u001b[0;36mMessagePassing.__lift__\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n\u001b[1;32m    171\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "logger = get_logger('log_experiments')\n",
    "seed_everything(seed=42)\n",
    "\n",
    "def run_experiment_gnn(database_name, \n",
    "                       K, \n",
    "                       hidden_channels, \n",
    "                       num_layers, \n",
    "                       p_dropout, \n",
    "                       Kc,\n",
    "                       docf, \n",
    "                       docst,\n",
    "                       activation, \n",
    "                       version,\n",
    "                       num_epochs):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        heterodata_description = f'{database_name}_K_{K}_Kc_{Kc}_docf_{str(docf)}_docst_{str(docst)}'\n",
    "        with open(f'./pickle_objects/preprocess/{database_name}/heterodata_pbg_{heterodata_description}_train.pickle', 'rb') as f:\n",
    "            heterodata_train = pickle.load(f)\n",
    "        with open(f'./pickle_objects/preprocess/{database_name}/heterodata_pbg_{heterodata_description}_test.pickle', 'rb') as f:\n",
    "            heterodata_test = pickle.load(f)\n",
    "                        \n",
    "        logger.info(f'Loaded preprocessed heterographs {heterodata_description}.')\n",
    "\n",
    "        training_description = f'{heterodata_description}_act_{activation}_ver_{version}'\n",
    "\n",
    "        df_experiment = run_heterognn_splitted(database_name=database_name,\n",
    "                           description=training_description, \n",
    "                           heterodata_train=heterodata_train,\n",
    "                           heterodata_test=heterodata_test,\n",
    "                           hidden_channels=hidden_channels,\n",
    "                           num_layers=num_layers,\n",
    "                           p_dropout=p_dropout,\n",
    "                           num_epochs=num_epochs, \n",
    "                           aggr='sum',\n",
    "                           version=version, \n",
    "                           activation=activation, \n",
    "                           verbose=True)\n",
    "        \n",
    "        loss_test, micro_test, acc_test, epoch_convergence = df_experiment\n",
    "        df = pd.DataFrame(columns=['database_name', 'K', 'Kc', 'docf', 'docst', 'hidden_channels', 'num_layers', 'p_dropout', 'activation', 'version', 'loss_test', 'micro_test', 'acc_test', 'epoch_convergence'])\n",
    "        output_list = [database_name, K, Kc, docf, docst, hidden_channels, num_layers, p_dropout, activation, version, loss_test, micro_test, acc_test, epoch_convergence]\n",
    "        row = pd.Series(output_list, index=df.columns)\n",
    "        df = df.append(row,ignore_index=True) \n",
    "        \n",
    "#         with open('./csv_objects/summary/experiments_summary.csv', 'a') as f:\n",
    "#             df.to_csv(f, mode='a', sep=';', decimal=',', index=False, header=f.tell()==0)\n",
    "        \n",
    "        logger.info(f'Executed experiments on {database_name} {training_description}. Results saved as pickle objects.')\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.info(f'Error occurred: \\n{e}')\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    databse_list = ['classic4']#['20ng', '20ng', 'bbcnews', 'reuters', 'classic4', 'nsf', 'webkb', 'agnews']\n",
    "    K = 50\n",
    "    hidden_channels = 400\n",
    "    num_layers = 3\n",
    "    p_dropout = 0.2\n",
    "    Kc = 400\n",
    "    docf = 'replace'\n",
    "    docst = 0.5\n",
    "    num_epochs = 1500\n",
    "    activation_list = ['fl']#['ce', 'fl']\n",
    "    gnn_version_list = [1, 2, 3, 4]\n",
    "    \n",
    "\n",
    "    logger.info('Running experiments on datasets with heterographs and GNNs.')\n",
    "\n",
    "    for database_name in databse_list:\n",
    "        for activation in activation_list:\n",
    "            for version in gnn_version_list:\n",
    "                run_experiment_gnn(database_name, \n",
    "                                  K, \n",
    "                                  hidden_channels, \n",
    "                                  num_layers, \n",
    "                                  p_dropout, \n",
    "                                  Kc,\n",
    "                                  docf, \n",
    "                                  docst,\n",
    "                                  activation, \n",
    "                                  version,\n",
    "                                  num_epochs)\n",
    "\n",
    "!zip -r /content/csv_objects.zip /content/csv_objects\n",
    "!cp /content/csv_objects.zip  /content/drive/MyDrive/project \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
